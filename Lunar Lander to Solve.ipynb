{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-01-14 11:48:30,621] Making new env: LunarLander-v2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00433598,  0.94139643,  0.43916426,  0.05219902, -0.00501745,\n",
       "       -0.09947715,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "NUMBER_OF_OBSERVATIONS=8\n",
    "NUMBER_OF_ACTIONS=4\n",
    "NUMBER_OF_GAMES_TO_PLAY=100\n",
    "NUMBER_OF_STEPS=40000\n",
    "MAX_MEMORY_LENGTH = 60000\n",
    "NUMBER_INITIAL_OBSERVATIONS = 0\n",
    "\n",
    "# One hot encoding array https://fr.wikipedia.org/wiki/Encodage_one-hot\n",
    "possible_actions = np.arange(0,NUMBER_OF_ACTIONS)\n",
    "actions_one_hot_encoding = np.zeros((NUMBER_OF_ACTIONS,NUMBER_OF_ACTIONS))\n",
    "actions_one_hot_encoding[np.arange(NUMBER_OF_ACTIONS),possible_actions] = 1\n",
    "\n",
    "# Create enviroment\n",
    "env = gym.make('LunarLander-v2')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# TODO\n",
    "# Define the function which returns the model, i.e the function approximator\n",
    "# You can find information here https://keras.io/models/sequential/\n",
    "def model():\n",
    "    return LinearRegression()\n",
    "\n",
    "def load_model(m, filename='model.pkl'):\n",
    "    return joblib.load(filename) \n",
    "\n",
    "def save_model(m, filename='model.pkl'):\n",
    "    joblib.dump(m, filename) \n",
    "\n",
    "# TODO\n",
    "# The probability under which a random action is performed\n",
    "# Try to find the balance between exploration and exploitation\n",
    "def get_epsilon(game_no, game_max_no):\n",
    "    return 0.5\n",
    "\n",
    "# The epsilon greedy policy\n",
    "# This function should return an action (0, 1, 2 or 3)\n",
    "# It should call the get_epsilon function\n",
    "# Under an epsilon probability, pick a random action\n",
    "# Otherwise, find the best action according to your model\n",
    "# You should predict the value of the vectors\n",
    "# [observation1, observation2, ... , action0] [observation1, observation2, ... , action1] etc up to the number of actions (4)\n",
    "def epsilon_greedy(env):\n",
    "    return env.action_space.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Game # 0  steps =  109  finished with headscore  [-2.33323997]\n",
      "Training  game#  0 memory size 111\n",
      "Game  0  FAILED ***\n",
      "Training Game # 1  steps =  86  finished with headscore  [ 2.24895935]\n",
      "Game  1  FAILED ***\n",
      "Training Game # 2  steps =  115  finished with headscore  [-0.74237472]\n",
      "Game  2  FAILED ***\n",
      "Training Game # 3  steps =  112  finished with headscore  [-0.99601052]\n",
      "Game  3  FAILED ***\n",
      "Training Game # 4  steps =  69  finished with headscore  [ 1.85466729]\n",
      "Game  4  FAILED ***\n",
      "Training Game # 5  steps =  62  finished with headscore  [-1.87614015]\n",
      "Game  5  FAILED ***\n",
      "Training Game # 6  steps =  114  finished with headscore  [ 1.10501145]\n",
      "Game  6  FAILED ***\n",
      "Training Game # 7  steps =  108  finished with headscore  [-0.09100531]\n",
      "Game  7  FAILED ***\n",
      "Training Game # 8  steps =  146  finished with headscore  [ 2.11829873]\n",
      "Game  8  FAILED ***\n",
      "Training Game # 9  steps =  84  finished with headscore  [-1.67579416]\n",
      "Game  9  FAILED ***\n",
      "Training Game # 10  steps =  80  finished with headscore  [-0.50287314]\n",
      "Training  game#  10 memory size 1107\n",
      "Game  10  FAILED ***\n",
      "Training Game # 11  steps =  68  finished with headscore  [-0.71074961]\n",
      "Game  11  FAILED ***\n",
      "Training Game # 12  steps =  88  finished with headscore  [-2.36944243]\n",
      "Game  12  FAILED ***\n",
      "Training Game # 13  steps =  61  finished with headscore  [ 1.43387938]\n",
      "Game  13  FAILED ***\n",
      "Training Game # 14  steps =  98  finished with headscore  [ 0.02542966]\n",
      "Game  14  FAILED ***\n",
      "Training Game # 15  steps =  72  finished with headscore  [-2.35267474]\n",
      "Game  15  FAILED ***\n",
      "Training Game # 16  steps =  75  finished with headscore  [ 0.41585039]\n",
      "Game  16  FAILED ***\n",
      "Training Game # 17  steps =  61  finished with headscore  [-0.53800945]\n",
      "Game  17  FAILED ***\n",
      "Training Game # 18  steps =  72  finished with headscore  [ 3.59780919]\n",
      "Game  18  FAILED ***\n",
      "Training Game # 19  steps =  94  finished with headscore  [ 1.06879768]\n",
      "Game  19  FAILED ***\n",
      "Training Game # 20  steps =  104  finished with headscore  [-0.00090605]\n",
      "Training  game#  20 memory size 1920\n",
      "Game  20  FAILED ***\n",
      "Training Game # 21  steps =  76  finished with headscore  [-1.82573744]\n",
      "Game  21  FAILED ***\n",
      "Training Game # 22  steps =  96  finished with headscore  [-1.28232788]\n",
      "Game  22  FAILED ***\n",
      "Training Game # 23  steps =  84  finished with headscore  [-0.11360712]\n",
      "Game  23  FAILED ***\n",
      "Training Game # 24  steps =  61  finished with headscore  [-1.56991125]\n",
      "Game  24  FAILED ***\n",
      "Training Game # 25  steps =  112  finished with headscore  [-2.78406324]\n",
      "Game  25  FAILED ***\n",
      "Training Game # 26  steps =  82  finished with headscore  [-1.76248593]\n",
      "Game  26  FAILED ***\n",
      "Training Game # 27  steps =  76  finished with headscore  [-2.23102316]\n",
      "Game  27  FAILED ***\n",
      "Training Game # 28  steps =  69  finished with headscore  [-0.59500719]\n",
      "Game  28  FAILED ***\n",
      "Training Game # 29  steps =  96  finished with headscore  [ 0.19835497]\n",
      "Game  29  FAILED ***\n",
      "Training Game # 30  steps =  75  finished with headscore  [-1.7984078]\n",
      "Training  game#  30 memory size 2767\n",
      "Game  30  FAILED ***\n",
      "Training Game # 31  steps =  88  finished with headscore  [-1.53488315]\n",
      "Game  31  FAILED ***\n",
      "Training Game # 32  steps =  66  finished with headscore  [-1.53898568]\n",
      "Game  32  FAILED ***\n",
      "Training Game # 33  steps =  97  finished with headscore  [-2.67149045]\n",
      "Game  33  FAILED ***\n",
      "Training Game # 34  steps =  109  finished with headscore  [-2.06809613]\n",
      "Game  34  FAILED ***\n",
      "Training Game # 35  steps =  73  finished with headscore  [-1.35803147]\n",
      "Game  35  FAILED ***\n",
      "Training Game # 36  steps =  116  finished with headscore  [ 1.4494483]\n",
      "Game  36  FAILED ***\n",
      "Training Game # 37  steps =  88  finished with headscore  [-2.41238758]\n",
      "Game  37  FAILED ***\n",
      "Training Game # 38  steps =  108  finished with headscore  [-2.5341095]\n",
      "Game  38  FAILED ***\n",
      "Training Game # 39  steps =  64  finished with headscore  [-1.92246719]\n",
      "Game  39  FAILED ***\n",
      "Training Game # 40  steps =  78  finished with headscore  [-0.56269319]\n",
      "Training  game#  40 memory size 3674\n",
      "Game  40  FAILED ***\n",
      "Training Game # 41  steps =  100  finished with headscore  [-2.21899938]\n",
      "Game  41  FAILED ***\n",
      "Training Game # 42  steps =  66  finished with headscore  [-1.56655584]\n",
      "Game  42  FAILED ***\n",
      "Training Game # 43  steps =  63  finished with headscore  [-0.57508025]\n",
      "Game  43  FAILED ***\n",
      "Training Game # 44  steps =  79  finished with headscore  [-1.7663674]\n",
      "Game  44  FAILED ***\n",
      "Training Game # 45  steps =  83  finished with headscore  [-1.3871339]\n",
      "Game  45  FAILED ***\n",
      "Training Game # 46  steps =  56  finished with headscore  [-1.45027237]\n",
      "Game  46  FAILED ***\n",
      "Training Game # 47  steps =  72  finished with headscore  [-1.7761023]\n",
      "Game  47  FAILED ***\n",
      "Training Game # 48  steps =  84  finished with headscore  [-0.9216601]\n",
      "Game  48  FAILED ***\n",
      "Training Game # 49  steps =  70  finished with headscore  [ 0.39421046]\n",
      "Game  49  FAILED ***\n",
      "Training Game # 50  steps =  116  finished with headscore  [-0.25767702]\n",
      "Training  game#  50 memory size 4483\n",
      "Game  50  FAILED ***\n",
      "Training Game # 51  steps =  88  finished with headscore  [ 0.61217162]\n",
      "Game  51  FAILED ***\n",
      "Training Game # 52  steps =  103  finished with headscore  [ 1.28766458]\n",
      "Game  52  FAILED ***\n",
      "Training Game # 53  steps =  73  finished with headscore  [-1.87518656]\n",
      "Game  53  FAILED ***\n",
      "Training Game # 54  steps =  139  finished with headscore  [-0.05380123]\n",
      "Game  54  FAILED ***\n",
      "Training Game # 55  steps =  94  finished with headscore  [-1.60195945]\n",
      "Game  55  FAILED ***\n",
      "Training Game # 56  steps =  118  finished with headscore  [ 0.32596705]\n",
      "Game  56  FAILED ***\n",
      "Training Game # 57  steps =  104  finished with headscore  [ 1.41923638]\n",
      "Game  57  FAILED ***\n",
      "Training Game # 58  steps =  85  finished with headscore  [-0.04063431]\n",
      "Game  58  FAILED ***\n",
      "Training Game # 59  steps =  63  finished with headscore  [ 1.10461225]\n",
      "Game  59  FAILED ***\n",
      "Training Game # 60  steps =  92  finished with headscore  [ 0.8889373]\n",
      "Training  game#  60 memory size 5462\n",
      "Game  60  FAILED ***\n",
      "Training Game # 61  steps =  73  finished with headscore  [-2.47085857]\n",
      "Game  61  FAILED ***\n",
      "Training Game # 62  steps =  117  finished with headscore  [-0.07996483]\n",
      "Game  62  FAILED ***\n",
      "Training Game # 63  steps =  82  finished with headscore  [-0.18827424]\n",
      "Game  63  FAILED ***\n",
      "Training Game # 64  steps =  71  finished with headscore  [-2.43441014]\n",
      "Game  64  FAILED ***\n",
      "Training Game # 65  steps =  96  finished with headscore  [ 0.44099108]\n",
      "Game  65  FAILED ***\n",
      "Training Game # 66  steps =  88  finished with headscore  [ 0.63481918]\n",
      "Game  66  FAILED ***\n",
      "Training Game # 67  steps =  82  finished with headscore  [-1.0766597]\n",
      "Game  67  FAILED ***\n",
      "Training Game # 68  steps =  98  finished with headscore  [ 1.76991764]\n",
      "Game  68  FAILED ***\n",
      "Training Game # 69  steps =  104  finished with headscore  [ 0.63608478]\n",
      "Game  69  FAILED ***\n",
      "Training Game # 70  steps =  89  finished with headscore  [-0.82222244]\n",
      "Training  game#  70 memory size 6382\n",
      "Game  70  FAILED ***\n",
      "Training Game # 71  steps =  101  finished with headscore  [-0.33154516]\n",
      "Game  71  FAILED ***\n",
      "Training Game # 72  steps =  97  finished with headscore  [ 2.18285522]\n",
      "Game  72  FAILED ***\n",
      "Training Game # 73  steps =  123  finished with headscore  [-2.46069539]\n",
      "Game  73  FAILED ***\n",
      "Training Game # 74  steps =  124  finished with headscore  [ 1.25613604]\n",
      "Game  74  FAILED ***\n",
      "Training Game # 75  steps =  80  finished with headscore  [ 3.87409081]\n",
      "Game  75  FAILED ***\n",
      "Training Game # 76  steps =  96  finished with headscore  [-1.86271606]\n",
      "Game  76  FAILED ***\n",
      "Training Game # 77  steps =  98  finished with headscore  [-1.87392762]\n",
      "Game  77  FAILED ***\n",
      "Training Game # 78  steps =  84  finished with headscore  [-1.57138115]\n",
      "Game  78  FAILED ***\n",
      "Training Game # 79  steps =  78  finished with headscore  [-1.41646565]\n",
      "Game  79  FAILED ***\n",
      "Training Game # 80  steps =  63  finished with headscore  [-2.60644982]\n",
      "Training  game#  80 memory size 7346\n",
      "Game  80  FAILED ***\n",
      "Training Game # 81  steps =  62  finished with headscore  [ 3.43483519]\n",
      "Game  81  FAILED ***\n",
      "Training Game # 82  steps =  114  finished with headscore  [ 1.05322755]\n",
      "Game  82  FAILED ***\n",
      "Training Game # 83  steps =  134  finished with headscore  [-4.85318338]\n",
      "Game  83  FAILED ***\n",
      "Training Game # 84  steps =  62  finished with headscore  [-2.41931646]\n",
      "Game  84  FAILED ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Game # 85  steps =  102  finished with headscore  [-2.28491041]\n",
      "Game  85  FAILED ***\n",
      "Training Game # 86  steps =  81  finished with headscore  [-1.1166503]\n",
      "Game  86  FAILED ***\n",
      "Training Game # 87  steps =  84  finished with headscore  [-2.56541479]\n",
      "Game  87  FAILED ***\n",
      "Training Game # 88  steps =  116  finished with headscore  [-4.4985511]\n",
      "Game  88  FAILED ***\n",
      "Training Game # 89  steps =  99  finished with headscore  [-2.34241708]\n",
      "Game  89  FAILED ***\n",
      "Training Game # 90  steps =  92  finished with headscore  [-0.96505456]\n",
      "Training  game#  90 memory size 8312\n",
      "Game  90  FAILED ***\n",
      "Training Game # 91  steps =  118  finished with headscore  [-3.93445344]\n",
      "Game  91  FAILED ***\n",
      "Training Game # 92  steps =  96  finished with headscore  [-4.69179282]\n",
      "Game  92  FAILED ***\n"
     ]
    }
   ],
   "source": [
    "#Initialize Memory Array data array \n",
    "memoryX = np.zeros(shape=(1,NUMBER_OF_OBSERVATIONS+NUMBER_OF_ACTIONS))\n",
    "memoryY = np.zeros(shape=(1,1))\n",
    "\n",
    "approximator = model()\n",
    "\n",
    "def calculate_q_values(rewards, b_discount):\n",
    "    rewards_length = len(rewards)\n",
    "    for i in range(0, rewards_length):\n",
    "        if i==0:\n",
    "            rewards[(rewards_length-1)-i] = rewards[(rewards_length-1)-i]\n",
    "        else:\n",
    "            rewards[(rewards_length-1)-i] = rewards[(rewards_length-1)-i]+b_discount*rewards[(rewards_length-1)-i+1]\n",
    "        if i==rewards_length-1:\n",
    "            print(\"Training Game #\",game, \" steps = \", step ,\" finished with headscore \", rewards[(rewards_length-1)-i])\n",
    "    return rewards\n",
    "\n",
    "def update_memory(memoryX, memoryY, X, y):\n",
    "    if memoryX.shape[0] == 1:\n",
    "        memoryX = X\n",
    "        memoryY = y\n",
    "    else:\n",
    "        #Add experience to memory\n",
    "        memoryX = np.concatenate((memoryX, X),axis=0)\n",
    "        memoryY = np.concatenate((memoryY, y),axis=0)\n",
    "        # if memory is full remove first element\n",
    "        if np.alen(memoryX) >= MAX_MEMORY_LENGTH:\n",
    "            for l in range(np.alen(X)):\n",
    "                memoryX = np.delete(memoryX, 0, axis=0)\n",
    "                memoryY = np.delete(memoryY, 0, axis=0)\n",
    "    return memoryX, memoryY\n",
    "\n",
    "for game in range(NUMBER_OF_GAMES_TO_PLAY):\n",
    "    # the vector that combines the environment and the action\n",
    "    X = np.zeros(shape=(1,NUMBER_OF_OBSERVATIONS+NUMBER_OF_ACTIONS))\n",
    "    y = np.zeros(shape=(1,1))\n",
    "    # reset the environment to start a new game\n",
    "    qs = env.reset()\n",
    "    for step in range (NUMBER_OF_STEPS):\n",
    "\n",
    "        action = epsilon_greedy(env)\n",
    "        env.render()\n",
    "        qs_a = np.concatenate((qs, actions_one_hot_encoding[action]), axis=0)        \n",
    "        observation,reward,done,info = env.step(action)\n",
    "\n",
    "        #observations = np.vstack(observations, observation)\n",
    "        #rewards = np.vstack(rewards, reward)\n",
    "                  \n",
    "        if step == 0:\n",
    "            X[0] = qs_a\n",
    "            y = np.array([reward])\n",
    "            memoryX[0] = qs_a\n",
    "            memoryY[0] = np.array([reward])\n",
    "        X = np.vstack((X,qs_a))\n",
    "        y = np.vstack((y, np.array([reward])))\n",
    "        \n",
    "        if done:\n",
    "            # calculate Q values from end to start, using the Bellman equation\n",
    "            # You need to find a good parameter for b_discount (look for the Bellman equation)\n",
    "            calculate_q_values(y, b_discount=0.0)\n",
    "            (memoryX, memoryY) = update_memory(memoryX, memoryY, X, y)\n",
    "        \n",
    "        # Update the states\n",
    "        qs=observation\n",
    "        # Train every X game after num_initial_observation\n",
    "        if done:\n",
    "            if game >= NUMBER_INITIAL_OBSERVATIONS and game%10 == 0 and game != 0:\n",
    "                print(\"Training  game# \", game,\"memory size\", memoryX.shape[0])\n",
    "                approximator.fit(memoryX,memoryY)\n",
    "                save_model(approximator)\n",
    "                env.reset()\n",
    "            if reward >= 0 and reward <99:\n",
    "                print(\"Game \",game,\" ended with positive reward \")\n",
    "            if reward > 50:\n",
    "                print(\"Game \", game,\" WON *** \" )\n",
    "            else:\n",
    "                print(\"Game \", game,\" FAILED ***\")\n",
    "            break\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
